---
title: "NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional
Generalization"
collection: publications
permalink: /publication/neuro-symbolic-concept-composer
image: "files/neuro-symbolic-concept-composer/img.png"
excerpt: 'Compositional generalization is crucial for artificial intelligence agents tackling intricate reasoning over vision and language (V\&L) problems. While neuro-symbolic methods have demonstrated potential in understanding compositional structures, they face challenges such as the need for symbolic domain representations that typically involve a set of predefined predicates, difficulties in deriving domain predicates from raw data, and the requirement for differentiable operations to compose primitive concepts. To address these issues, we propose NeSyCoCo, which is built on the existing neuro-symbolic frameworks that leverage large language models (LLMs) for obtaining symbolic representations of the domain and map them to differentiable neural computations for V\&L reasoning. Our approach a) augments the natural language inputs with their dependency structure to improve the accuracy of symbolic representations, b) utilizes distributed word representations for handling the variety of linguistically motivated logical predicates that are linked to neural modules, and c) utilizes soft composition of normalized predicate scores for better semantic alignment between symbolic compositions and differentiable operations. NeSyCoCo achieves state-of-the-art results on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks, as well as the CLEVR vision-language benchmark. It also maintains high accuracy with new, similar concepts in the CLEVR-SYN benchmark.'
date: 2024-12-12
venue: 'Preprint'
paperurl: 'github.com'
#citation:
---

Compositional generalization is crucial for artificial intelligence agents tackling intricate reasoning over vision and language (V\&L) problems. While neuro-symbolic methods have demonstrated potential in understanding compositional structures, they face challenges such as the need for symbolic domain representations that typically involve a set of predefined predicates, difficulties in deriving domain predicates from raw data, and the requirement for differentiable operations to compose primitive concepts. To address these issues, we propose NeSyCoCo, which is built on the existing neuro-symbolic frameworks that leverage large language models (LLMs) for obtaining symbolic representations of the domain and map them to differentiable neural computations for V\&L reasoning. Our approach a) augments the natural language inputs with their dependency structure to improve the accuracy of symbolic representations, b) utilizes distributed word representations for handling the variety of linguistically motivated logical predicates that are linked to neural modules, and c) utilizes soft composition of normalized predicate scores for better semantic alignment between symbolic compositions and differentiable operations. NeSyCoCo achieves state-of-the-art results on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks, as well as the CLEVR vision-language benchmark. It also maintains high accuracy with new, similar concepts in the CLEVR-SYN benchmark.


